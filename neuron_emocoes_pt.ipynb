{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9664b6",
   "metadata": {},
   "source": [
    "\n",
    "# Neuron - Classificação de Emoções em Português\n",
    "\n",
    "Este notebook implementa o pipeline completo de **Machine Learning** para o projeto Neuron:\n",
    "\n",
    "1. Carregamento do dataset de frases em português.\n",
    "2. Análise exploratória simples.\n",
    "3. Pré-processamento de texto (PT-BR).\n",
    "4. Criação de dois modelos de IA:\n",
    "   - **Modelo 1**: classificação de **emoções** (`alegria, tristeza, raiva, medo, amor, surpresa`).\n",
    "   - **Modelo 2**: classificação de **sentimento** (`positivo` x `negativo`).\n",
    "5. Salvamento dos modelos em arquivo `.pkl`.\n",
    "6. Exemplo de uso do modelo para rotular uma conversa ao longo de vários dias e gerar gráficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d88caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Executar apenas na primeira vez no ambiente\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('rslp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcf070",
   "metadata": {},
   "source": [
    "## 1. Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a99bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>emocao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoje o time está bem animado com o resultado d...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fiquei muito feliz com o feedback positivo do ...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estou empolgado com as novas funcionalidades q...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O clima na empresa hoje está leve e divertido.</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adorei participar da reunião de brainstorming,...</td>\n",
       "      <td>alegria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto   emocao\n",
       "0  Hoje o time está bem animado com o resultado d...  alegria\n",
       "1  Fiquei muito feliz com o feedback positivo do ...  alegria\n",
       "2  Estou empolgado com as novas funcionalidades q...  alegria\n",
       "3     O clima na empresa hoje está leve e divertido.  alegria\n",
       "4  Adorei participar da reunião de brainstorming,...  alegria"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ajuste o caminho se precisar\n",
    "df = pd.read_csv(\"dados_humor_neuron_pt.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53473a",
   "metadata": {},
   "source": [
    "## 2. Análise exploratória simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e892bfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emocao\n",
       "alegria     8\n",
       "tristeza    8\n",
       "raiva       8\n",
       "medo        8\n",
       "amor        8\n",
       "surpresa    8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emocao'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fcf23",
   "metadata": {},
   "source": [
    "## 3. Criar coluna de sentimento (positivo/negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e80036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>emocao</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoje o time está bem animado com o resultado d...</td>\n",
       "      <td>alegria</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fiquei muito feliz com o feedback positivo do ...</td>\n",
       "      <td>alegria</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estou empolgado com as novas funcionalidades q...</td>\n",
       "      <td>alegria</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O clima na empresa hoje está leve e divertido.</td>\n",
       "      <td>alegria</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adorei participar da reunião de brainstorming,...</td>\n",
       "      <td>alegria</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto   emocao sentimento\n",
       "0  Hoje o time está bem animado com o resultado d...  alegria   positivo\n",
       "1  Fiquei muito feliz com o feedback positivo do ...  alegria   positivo\n",
       "2  Estou empolgado com as novas funcionalidades q...  alegria   positivo\n",
       "3     O clima na empresa hoje está leve e divertido.  alegria   positivo\n",
       "4  Adorei participar da reunião de brainstorming,...  alegria   positivo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "map_sent = {\n",
    "    \"alegria\": \"positivo\",\n",
    "    \"amor\": \"positivo\",\n",
    "    \"surpresa\": \"positivo\",\n",
    "    \"tristeza\": \"negativo\",\n",
    "    \"raiva\": \"negativo\",\n",
    "    \"medo\": \"negativo\",\n",
    "}\n",
    "\n",
    "df[\"sentimento\"] = df[\"emocao\"].map(map_sent)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f317d",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento de texto em PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16abfc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\tiago/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\tiago\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\corpus\\util.py:84\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\tiago/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\tiago\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stopwords_pt = \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mportuguese\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      2\u001b[39m stemmer = RSLPStemmer()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_pt\u001b[39m(texto: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\corpus\\util.py:120\u001b[39m, in \u001b[36mLazyCorpusLoader.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLazyCorpusLoader object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\corpus\\util.py:86\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     84\u001b[39m             root = nltk.data.find(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.subdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[32m     89\u001b[39m corpus = \u001b[38;5;28mself\u001b[39m.__reader_cls(root, *\u001b[38;5;28mself\u001b[39m.__args, **\u001b[38;5;28mself\u001b[39m.__kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\corpus\\util.py:81\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\tiago/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\tiago\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
    "stemmer = RSLPStemmer()\n",
    "\n",
    "def preprocess_pt(texto: str) -> str:\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"[^a-záéíóúâêôãõç\\s]\", \" \", texto)\n",
    "    tokens = texto.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords_pt]\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"texto_limpo\"] = df[\"texto\"].apply(preprocess_pt)\n",
    "df[[\"texto\", \"texto_limpo\", \"emocao\", \"sentimento\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94731d0c",
   "metadata": {},
   "source": [
    "## 5. Separar treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7aad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_emocao_train, y_emocao_test = train_test_split(\n",
    "    df[\"texto_limpo\"], df[\"emocao\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"emocao\"]\n",
    ")\n",
    "\n",
    "_, _, y_sent_train, y_sent_test = train_test_split(\n",
    "    df[\"texto_limpo\"], df[\"sentimento\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"sentimento\"]\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8458c84",
   "metadata": {},
   "source": [
    "## 6. Vetorização TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec  = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vec.shape, X_test_vec.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e6619",
   "metadata": {},
   "source": [
    "## 7. Modelo 1 – Classificação de Emoções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_emocao = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
    "modelo_emocao.fit(X_train_vec, y_emocao_train)\n",
    "\n",
    "y_pred_emocao = modelo_emocao.predict(X_test_vec)\n",
    "print(\"Accuracy EMOÇÃO:\", accuracy_score(y_emocao_test, y_pred_emocao))\n",
    "print(classification_report(y_emocao_test, y_pred_emocao))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3304b",
   "metadata": {},
   "source": [
    "## 8. Modelo 2 – Classificação de Sentimento (positivo/negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_sentimento = LogisticRegression(max_iter=1000)\n",
    "modelo_sentimento.fit(X_train_vec, y_sent_train)\n",
    "\n",
    "y_pred_sent = modelo_sentimento.predict(X_test_vec)\n",
    "print(\"Accuracy SENTIMENTO:\", accuracy_score(y_sent_test, y_pred_sent))\n",
    "print(classification_report(y_sent_test, y_pred_sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efcdcc",
   "metadata": {},
   "source": [
    "## 9. Salvar modelos em arquivo `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574305b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artefatos = {\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"modelo_emocao\": modelo_emocao,\n",
    "    \"modelo_sentimento\": modelo_sentimento,\n",
    "}\n",
    "\n",
    "with open(\"modelos_neuron_pt.pkl\", \"wb\") as f:\n",
    "    pickle.dump(artefatos, f)\n",
    "\n",
    "print(\"Modelos salvos em 'modelos_neuron_pt.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ee9f7",
   "metadata": {},
   "source": [
    "## 10. Exemplo – Classificar uma conversa e gerar análise por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c66fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carrega modelos (caso esteja em outro ambiente)\n",
    "with open(\"modelos_neuron_pt.pkl\", \"rb\") as f:\n",
    "    artefatos2 = pickle.load(f)\n",
    "\n",
    "vectorizer2 = artefatos2[\"vectorizer\"]\n",
    "modelo_emocao2 = artefatos2[\"modelo_emocao\"]\n",
    "modelo_sent2 = artefatos2[\"modelo_sentimento\"]\n",
    "\n",
    "# Exemplo de conversa com timestamps\n",
    "dados_conversa = [\n",
    "    {\"timestamp\": \"2025-11-14 09:10:00\", \"texto\": \"Bom dia, estou bem cansado e desmotivado hoje.\"},\n",
    "    {\"timestamp\": \"2025-11-14 11:30:00\", \"texto\": \"A reunião foi ótima, estou animado com o resultado.\"},\n",
    "    {\"timestamp\": \"2025-11-15 10:05:00\", \"texto\": \"Estou preocupado com o prazo, com medo de atrasar.\"},\n",
    "    {\"timestamp\": \"2025-11-15 16:40:00\", \"texto\": \"Adorei o feedback do cliente, fiquei muito feliz.\"},\n",
    "]\n",
    "\n",
    "df_msgs = pd.DataFrame(dados_conversa)\n",
    "df_msgs[\"timestamp\"] = pd.to_datetime(df_msgs[\"timestamp\"])\n",
    "df_msgs[\"data\"] = df_msgs[\"timestamp\"].dt.date\n",
    "\n",
    "df_msgs[\"texto_limpo\"] = df_msgs[\"texto\"].apply(preprocess_pt)\n",
    "X_msgs = vectorizer2.transform(df_msgs[\"texto_limpo\"])\n",
    "\n",
    "df_msgs[\"emocao\"] = modelo_emocao2.predict(X_msgs)\n",
    "df_msgs[\"sentimento\"] = modelo_sent2.predict(X_msgs)\n",
    "\n",
    "df_msgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1aedf",
   "metadata": {},
   "source": [
    "### Gráficos de emoções e sentimento por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9661ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emocoes_por_dia = (\n",
    "    df_msgs.groupby([\"data\", \"emocao\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"quantidade\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(data=emocoes_por_dia, x=\"data\", y=\"quantidade\", hue=\"emocao\", marker=\"o\")\n",
    "plt.title(\"Emoções por dia\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "w\n",
    "sent_por_dia = (\n",
    "    df_msgs.groupby([\"data\", \"sentimento\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"quantidade\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=sent_por_dia, x=\"data\", y=\"quantidade\", hue=\"sentimento\")\n",
    "plt.title(\"Sentimento positivo/negativo por dia\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
