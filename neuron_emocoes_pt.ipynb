{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9664b6",
   "metadata": {},
   "source": [
    "\n",
    "# Neuron - Classificação de Emoções em Português\n",
    "\n",
    "Este notebook implementa o pipeline completo de **Machine Learning** para o projeto Neuron:\n",
    "\n",
    "1. Carregamento do dataset de frases em português.\n",
    "2. Análise exploratória simples.\n",
    "3. Pré-processamento de texto (PT-BR).\n",
    "4. Criação de dois modelos de IA:\n",
    "   - **Modelo 1**: classificação de **emoções** (`alegria, tristeza, raiva, medo, amor, surpresa`).\n",
    "   - **Modelo 2**: classificação de **sentimento** (`positivo` x `negativo`).\n",
    "5. Salvamento dos modelos em arquivo `.pkl`.\n",
    "6. Exemplo de uso do modelo para rotular uma conversa ao longo de vários dias e gerar gráficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Executar apenas na primeira vez no ambiente\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('rslp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcf070",
   "metadata": {},
   "source": [
    "## 1. Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a99bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ajuste o caminho se precisar\n",
    "df = pd.read_csv(\"dados_humor_neuron_pt.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53473a",
   "metadata": {},
   "source": [
    "## 2. Análise exploratória simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emocao'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fcf23",
   "metadata": {},
   "source": [
    "## 3. Criar coluna de sentimento (positivo/negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e80036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_sent = {\n",
    "    \"alegria\": \"positivo\",\n",
    "    \"amor\": \"positivo\",\n",
    "    \"surpresa\": \"positivo\",\n",
    "    \"tristeza\": \"negativo\",\n",
    "    \"raiva\": \"negativo\",\n",
    "    \"medo\": \"negativo\",\n",
    "}\n",
    "\n",
    "df[\"sentimento\"] = df[\"emocao\"].map(map_sent)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f317d",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento de texto em PT-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16abfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
    "stemmer = RSLPStemmer()\n",
    "\n",
    "def preprocess_pt(texto: str) -> str:\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"[^a-záéíóúâêôãõç\\s]\", \" \", texto)\n",
    "    tokens = texto.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords_pt]\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"texto_limpo\"] = df[\"texto\"].apply(preprocess_pt)\n",
    "df[[\"texto\", \"texto_limpo\", \"emocao\", \"sentimento\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94731d0c",
   "metadata": {},
   "source": [
    "## 5. Separar treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7aad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_emocao_train, y_emocao_test = train_test_split(\n",
    "    df[\"texto_limpo\"], df[\"emocao\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"emocao\"]\n",
    ")\n",
    "\n",
    "_, _, y_sent_train, y_sent_test = train_test_split(\n",
    "    df[\"texto_limpo\"], df[\"sentimento\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"sentimento\"]\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8458c84",
   "metadata": {},
   "source": [
    "## 6. Vetorização TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec  = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vec.shape, X_test_vec.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e6619",
   "metadata": {},
   "source": [
    "## 7. Modelo 1 – Classificação de Emoções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_emocao = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
    "modelo_emocao.fit(X_train_vec, y_emocao_train)\n",
    "\n",
    "y_pred_emocao = modelo_emocao.predict(X_test_vec)\n",
    "print(\"Accuracy EMOÇÃO:\", accuracy_score(y_emocao_test, y_pred_emocao))\n",
    "print(classification_report(y_emocao_test, y_pred_emocao))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3304b",
   "metadata": {},
   "source": [
    "## 8. Modelo 2 – Classificação de Sentimento (positivo/negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_sentimento = LogisticRegression(max_iter=1000)\n",
    "modelo_sentimento.fit(X_train_vec, y_sent_train)\n",
    "\n",
    "y_pred_sent = modelo_sentimento.predict(X_test_vec)\n",
    "print(\"Accuracy SENTIMENTO:\", accuracy_score(y_sent_test, y_pred_sent))\n",
    "print(classification_report(y_sent_test, y_pred_sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efcdcc",
   "metadata": {},
   "source": [
    "## 9. Salvar modelos em arquivo `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574305b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artefatos = {\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"modelo_emocao\": modelo_emocao,\n",
    "    \"modelo_sentimento\": modelo_sentimento,\n",
    "}\n",
    "\n",
    "with open(\"modelos_neuron_pt.pkl\", \"wb\") as f:\n",
    "    pickle.dump(artefatos, f)\n",
    "\n",
    "print(\"Modelos salvos em 'modelos_neuron_pt.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ee9f7",
   "metadata": {},
   "source": [
    "## 10. Exemplo – Classificar uma conversa e gerar análise por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c66fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carrega modelos (caso esteja em outro ambiente)\n",
    "with open(\"modelos_neuron_pt.pkl\", \"rb\") as f:\n",
    "    artefatos2 = pickle.load(f)\n",
    "\n",
    "vectorizer2 = artefatos2[\"vectorizer\"]\n",
    "modelo_emocao2 = artefatos2[\"modelo_emocao\"]\n",
    "modelo_sent2 = artefatos2[\"modelo_sentimento\"]\n",
    "\n",
    "# Exemplo de conversa com timestamps\n",
    "dados_conversa = [\n",
    "    {\"timestamp\": \"2025-11-14 09:10:00\", \"texto\": \"Bom dia, estou bem cansado e desmotivado hoje.\"},\n",
    "    {\"timestamp\": \"2025-11-14 11:30:00\", \"texto\": \"A reunião foi ótima, estou animado com o resultado.\"},\n",
    "    {\"timestamp\": \"2025-11-15 10:05:00\", \"texto\": \"Estou preocupado com o prazo, com medo de atrasar.\"},\n",
    "    {\"timestamp\": \"2025-11-15 16:40:00\", \"texto\": \"Adorei o feedback do cliente, fiquei muito feliz.\"},\n",
    "]\n",
    "\n",
    "df_msgs = pd.DataFrame(dados_conversa)\n",
    "df_msgs[\"timestamp\"] = pd.to_datetime(df_msgs[\"timestamp\"])\n",
    "df_msgs[\"data\"] = df_msgs[\"timestamp\"].dt.date\n",
    "\n",
    "df_msgs[\"texto_limpo\"] = df_msgs[\"texto\"].apply(preprocess_pt)\n",
    "X_msgs = vectorizer2.transform(df_msgs[\"texto_limpo\"])\n",
    "\n",
    "df_msgs[\"emocao\"] = modelo_emocao2.predict(X_msgs)\n",
    "df_msgs[\"sentimento\"] = modelo_sent2.predict(X_msgs)\n",
    "\n",
    "df_msgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1aedf",
   "metadata": {},
   "source": [
    "### Gráficos de emoções e sentimento por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9661ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emocoes_por_dia = (\n",
    "    df_msgs.groupby([\"data\", \"emocao\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"quantidade\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(data=emocoes_por_dia, x=\"data\", y=\"quantidade\", hue=\"emocao\", marker=\"o\")\n",
    "plt.title(\"Emoções por dia\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sent_por_dia = (\n",
    "    df_msgs.groupby([\"data\", \"sentimento\"])\n",
    "           .size()\n",
    "           .reset_index(name=\"quantidade\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=sent_por_dia, x=\"data\", y=\"quantidade\", hue=\"sentimento\")\n",
    "plt.title(\"Sentimento positivo/negativo por dia\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
